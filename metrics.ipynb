{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f508100-2ce7-4606-aa83-0be0c8e4a8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================\n",
    "# NATURAL TEXT INPUT\n",
    "# =======================\n",
    "\n",
    "import os\n",
    "import json\n",
    "import csv\n",
    "import logging\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from typing import Dict, Optional\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "\n",
    "class Config:\n",
    "    def __init__(self):\n",
    "        # Directory containing the JSON files\n",
    "        self.data_directory = './data/encoded/caesar-cipher/natural/'\n",
    "        # Path to the configuration file\n",
    "        self.config_file_path = './caesar-cipher-experiments-log-natural-text.txt'\n",
    "        # CSV output file for aggregated metrics\n",
    "        self.csv_file_result = 'caesar-cipher-natural-text-benchmark-result.csv'\n",
    "        # Text file containing all details\n",
    "        self.output_details_file = 'caesar-cipher-natural-text-benchmark-process.txt'\n",
    "\n",
    "class CaesarCipherTest:\n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config\n",
    "        self.directory = self.config.data_directory\n",
    "        self.config_file = self.config.config_file_path\n",
    "        # Parse config file once for metadata\n",
    "        self.config_data = self.parse_config_file()\n",
    "\n",
    "        # Exponent for weighting sequences by their word length\n",
    "        self.word_weight_exponent = 2\n",
    "\n",
    "        # Accumulate final (file-level) results for the CSV\n",
    "        self.file_level_results = []\n",
    "        \n",
    "        # Clear or create the output details file at the start\n",
    "        with open(self.config.output_details_file, 'w', encoding='utf-8') as f:\n",
    "            f.write(\"Comprehensive operation details for random text results:\\n\\n\")\n",
    "\n",
    "    def parse_config_file(self) -> Dict[str, Dict[str, str]]:\n",
    "        config_data = {}\n",
    "        try:\n",
    "            with open(self.config_file, 'r') as f:\n",
    "                for line in f:\n",
    "                    line = line.strip()\n",
    "                    if line:\n",
    "                        timestamp = self.extract_timestamp(line)\n",
    "                        fields = self.parse_filename(line)\n",
    "                        config_data[timestamp] = fields\n",
    "        except FileNotFoundError:\n",
    "            logging.error(f\"Config file {self.config_file} not found.\")\n",
    "        return config_data\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_timestamp(filename: str) -> str:\n",
    "        \"\"\"\n",
    "        Example: 20230101_122345_some-other-stuff -> timestamp would be 20230101_122345\n",
    "        \"\"\"\n",
    "        parts = filename.split('_')\n",
    "        if len(parts) >= 2:\n",
    "            return f\"{parts[0]}_{parts[1]}\"\n",
    "        return parts[0]\n",
    "\n",
    "    @staticmethod\n",
    "    def parse_filename(filename: str) -> Dict[str, str]:\n",
    "        \"\"\"\n",
    "        A robust approach that handles both Llama-like (__0.01_64) \n",
    "        and Mistral-like (_0.01_64) suffixes.\n",
    "        \"\"\"\n",
    "        if filename.endswith('.json'):\n",
    "            filename = filename[:-5]\n",
    "\n",
    "        pattern = r'^(.*)_([\\d\\.]+)_(\\d+)$'\n",
    "        match = re.match(pattern, filename)\n",
    "        if match:\n",
    "            pre_model_info = match.group(1)\n",
    "            temperature   = match.group(2)\n",
    "            max_token     = match.group(3)\n",
    "        else:\n",
    "            pre_model_info = filename\n",
    "            temperature    = ''\n",
    "            max_token      = ''\n",
    "\n",
    "        pre_fields = pre_model_info.split('_')\n",
    "\n",
    "        date        = pre_fields[0] if len(pre_fields) > 0 else ''\n",
    "        time        = pre_fields[1] if len(pre_fields) > 1 else ''\n",
    "        samples     = pre_fields[2] if len(pre_fields) > 2 else ''\n",
    "        shift       = pre_fields[3] if len(pre_fields) > 3 else ''\n",
    "        prompt_type = '_'.join(pre_fields[4:6]) if len(pre_fields) > 5 else ''\n",
    "        method      = pre_fields[6] if len(pre_fields) > 6 else ''\n",
    "\n",
    "        shot_and_model_name_parts = pre_fields[7:]\n",
    "        shot_and_model_name       = '_'.join(shot_and_model_name_parts)\n",
    "\n",
    "        if '-' in shot_and_model_name:\n",
    "            shot, model_name = shot_and_model_name.split('-', 1)\n",
    "        else:\n",
    "            shot = ''\n",
    "            model_name = shot_and_model_name\n",
    "\n",
    "        if model_name.startswith('models--'):\n",
    "            model_name = model_name[len('models--'):]\n",
    "            model_parts = model_name.split('--')\n",
    "            model_name  = model_parts[-1]\n",
    "        model_name = model_name.rstrip('_')\n",
    "\n",
    "        return {\n",
    "            'date': date,\n",
    "            'time': time,\n",
    "            'samples': samples,\n",
    "            'shift': shift,\n",
    "            'prompt_type': prompt_type,\n",
    "            'method': method,\n",
    "            'shot': shot,\n",
    "            'model_name': model_name,\n",
    "            'temperature': temperature,\n",
    "            'max_token': max_token\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def levenshtein_distance(s1: str, s2: str) -> int:\n",
    "        \"\"\"\n",
    "        Compute the Levenshtein edit distance between two strings s1 and s2\n",
    "        (minimum number of single-character edits).\n",
    "        \"\"\"\n",
    "        if not s1:\n",
    "            return len(s2)\n",
    "        if not s2:\n",
    "            return len(s1)\n",
    "\n",
    "        len_s1 = len(s1)\n",
    "        len_s2 = len(s2)\n",
    "\n",
    "        dp = [[0] * (len_s2 + 1) for _ in range(len_s1 + 1)]\n",
    "\n",
    "        for i in range(len_s1 + 1):\n",
    "            dp[i][0] = i\n",
    "        for j in range(len_s2 + 1):\n",
    "            dp[0][j] = j\n",
    "\n",
    "        for i in range(1, len_s1 + 1):\n",
    "            for j in range(1, len_s2 + 1):\n",
    "                cost = 0 if s1[i-1] == s2[j-1] else 1\n",
    "                dp[i][j] = min(\n",
    "                    dp[i-1][j] + 1,       # deletion\n",
    "                    dp[i][j-1] + 1,       # insertion\n",
    "                    dp[i-1][j-1] + cost   # substitution\n",
    "                )\n",
    "\n",
    "        return dp[len_s1][len_s2]\n",
    "\n",
    "    def compute_per_record_metrics(self, cipher_text: str, gold_label: str) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Compute per-record metrics:\n",
    "          1) Levenshtein Error Rate: dist / len(gold_label)\n",
    "          2) Character Error Rate:   1 - (# matched chars / len(gold_label))\n",
    "          3) Word Accuracy (raw fraction for a single record)\n",
    "          4) Sentence Accuracy: 1.0 if exact match else 0.0\n",
    "        \"\"\"\n",
    "        gold_len = len(gold_label)\n",
    "        \n",
    "        # 1) Levenshtein Error Rate\n",
    "        if gold_len > 0:\n",
    "            dist = self.levenshtein_distance(cipher_text, gold_label)\n",
    "            levenshtein_error_rate = dist / gold_len\n",
    "            # Cap the Levenshtein Error Rate at 100 if it exceeds this threshold\n",
    "            if levenshtein_error_rate > 1:\n",
    "                levenshtein_error_rate = 1.0000\n",
    "                dist = gold_len\n",
    "        else:\n",
    "            dist = 0\n",
    "            levenshtein_error_rate = 0.0\n",
    "\n",
    "        # 2) Character Error Rate\n",
    "        matched_chars = 0\n",
    "        for i in range(gold_len):\n",
    "            if i < len(cipher_text) and cipher_text[i] == gold_label[i]:\n",
    "                matched_chars += 1\n",
    "\n",
    "        if gold_len > 0:\n",
    "            character_error_rate = 1 - (matched_chars / gold_len)\n",
    "        else:\n",
    "            character_error_rate = 0.0\n",
    "\n",
    "        # 3) Word Accuracy (unweighted, just per-record fraction)\n",
    "        gold_words = gold_label.split()\n",
    "        pred_words = cipher_text.split()\n",
    "        matched_words = sum(gw == pw for gw, pw in zip(gold_words, pred_words))\n",
    "        gold_words_len = len(gold_words)\n",
    "\n",
    "        if gold_words_len > 0:\n",
    "            word_accuracy = matched_words / gold_words_len\n",
    "        else:\n",
    "            word_accuracy = 0.0\n",
    "\n",
    "        # 4) Sentence Accuracy\n",
    "        sentence_accuracy = 1.0 if cipher_text == gold_label else 0.0\n",
    "\n",
    "        return {\n",
    "            'levenshtein_error_rate': levenshtein_error_rate,\n",
    "            'character_error_rate': character_error_rate,\n",
    "            'word_accuracy': word_accuracy,     # raw fraction for this record\n",
    "            'sentence_accuracy': sentence_accuracy,\n",
    "            # Additional for file-level weighting\n",
    "            'levenshtein_distance': dist,\n",
    "            'matched_chars': matched_chars,\n",
    "            'gold_length': gold_len,\n",
    "            'matched_words': matched_words,\n",
    "            'gold_words_len': gold_words_len\n",
    "        }\n",
    "\n",
    "    def process_json_file(self, filepath: str, fields: Dict[str, str]) -> Optional[Dict[str, float]]:\n",
    "        \"\"\"\n",
    "        Process a single JSON file:\n",
    "         - For each record: compute per-record metrics and log them.\n",
    "         - For file-level: \n",
    "             * Weighted word accuracy (using L^k).\n",
    "             * Weighted Levenshtein and Character Error Rate.\n",
    "             * Average Sentence Accuracy.\n",
    "             * NEW: total matched words vs. total gold words => file-level average word accuracy.\n",
    "        \"\"\"\n",
    "        filename = os.path.basename(filepath)\n",
    "        try:\n",
    "            with open(filepath, 'r', encoding='utf-8') as f:\n",
    "                content = f.read().strip()\n",
    "                if not content:\n",
    "                    logging.warning(f\"Skipping empty file: {filename}\")\n",
    "                    return None\n",
    "                data = json.loads(content)\n",
    "        except (json.JSONDecodeError, FileNotFoundError):\n",
    "            logging.error(f\"Error reading or decoding JSON in file: {filename}\")\n",
    "            return None\n",
    "\n",
    "        if not isinstance(data, list):\n",
    "            logging.error(f\"File {filename} does not contain a list of records.\")\n",
    "            return None\n",
    "\n",
    "        # Accumulators for file-level (weighted or otherwise)\n",
    "        total_levenshtein_distance = 0\n",
    "        total_matched_chars = 0\n",
    "        total_gold_chars = 0\n",
    "\n",
    "        # Weighted Word Accuracy accumulators\n",
    "        sum_weighted_word_contrib = 0.0\n",
    "        sum_length_weights = 0.0\n",
    "\n",
    "        # Sentence accuracy accumulators\n",
    "        sum_sentence_accuracy = 0.0\n",
    "        record_count = 0\n",
    "\n",
    "        # accumulators for average word accuracy\n",
    "        total_matched_words = 0\n",
    "        total_gold_words = 0\n",
    "\n",
    "        # Start logging to the details file\n",
    "        with open(self.config.output_details_file, 'a', encoding='utf-8') as out_f:\n",
    "            out_f.write(f\"=== Processing file: {filename} ===\\n\")\n",
    "            out_f.write(f\"Model name: {fields.get('model_name', '')}, Shift: {fields.get('shift', '')}, \"\n",
    "                        f\"Prompt Type: {fields.get('prompt_type', '')}, Temperature: {fields.get('temperature', '')}, \"\n",
    "                        f\"Max Token: {fields.get('max_token', '')}\\n\\n\")\n",
    "\n",
    "            # k exponent for weighting word accuracy\n",
    "            k = self.word_weight_exponent\n",
    "\n",
    "            # Process each record\n",
    "            for idx, record in enumerate(data, start=1):\n",
    "                cipher_text = record.get(\"cipher_text\", \"\").strip()\n",
    "                gold_label = record.get(\"gold_label\", \"\").strip()\n",
    "\n",
    "                if not cipher_text and not gold_label:\n",
    "                    continue\n",
    "\n",
    "                metrics = self.compute_per_record_metrics(cipher_text, gold_label)\n",
    "\n",
    "                # Basic record-level fraction\n",
    "                record_word_acc = metrics['word_accuracy']\n",
    "                L_i = metrics['gold_words_len']\n",
    "\n",
    "                # Weight factor = (L_i^k)\n",
    "                length_weight = (L_i ** k)\n",
    "                # Weighted contribution for word accuracy\n",
    "                weighted_contribution = length_weight * record_word_acc\n",
    "\n",
    "                # Accumulate for file-level\n",
    "                total_levenshtein_distance += metrics['levenshtein_distance']\n",
    "                total_matched_chars += metrics['matched_chars']\n",
    "                total_gold_chars += metrics['gold_length']\n",
    "\n",
    "                # Accumulate for average word accuracy\n",
    "                total_matched_words += metrics['matched_words']\n",
    "                total_gold_words += metrics['gold_words_len']\n",
    "\n",
    "                # Weighted Word Accuracy sums\n",
    "                sum_weighted_word_contrib += weighted_contribution\n",
    "                sum_length_weights += length_weight\n",
    "\n",
    "                sum_sentence_accuracy += metrics['sentence_accuracy']\n",
    "                record_count += 1\n",
    "\n",
    "                # Log per-record details\n",
    "                out_f.write(f\"Record #{idx}\\n\")\n",
    "                out_f.write(f\"  cipher_text: {cipher_text}\\n\")\n",
    "                out_f.write(f\"  gold_label:  {gold_label}\\n\")\n",
    "                out_f.write(f\"  Levenshtein Error Rate: {metrics['levenshtein_error_rate']:.4f}\\n\")\n",
    "                out_f.write(f\"  Character Error Rate:   {metrics['character_error_rate']:.4f}\\n\")\n",
    "                out_f.write(f\"  Word Accuracy (record, raw): {record_word_acc:.4f}\\n\")\n",
    "                out_f.write(f\"  Sentence Accuracy: {metrics['sentence_accuracy']:.4f}\\n\")\n",
    "\n",
    "                # print matched chars, matched words, gold chars, gold words\n",
    "                out_f.write(f\"  matched_characters: {metrics['matched_chars']}\\n\")\n",
    "                out_f.write(f\"  gold_characters:    {metrics['gold_length']}\\n\")\n",
    "                out_f.write(f\"  matched_words:      {metrics['matched_words']}\\n\")\n",
    "                out_f.write(f\"  gold_words_len:     {metrics['gold_words_len']}\\n\")\n",
    "\n",
    "                # Show the weighting details\n",
    "                out_f.write(f\"  Word length (L_i): {L_i},  k={k},  Weight factor = L_i^k = {length_weight}\\n\")\n",
    "                out_f.write(f\"  Weighted Word Contribution = {length_weight:.2f} * {record_word_acc:.4f} = {weighted_contribution:.4f}\\n\\n\")\n",
    "\n",
    "            # Final file-level Levenshtein Error Rate\n",
    "            if total_gold_chars > 0:\n",
    "                file_levenshtein_error_rate = total_levenshtein_distance / total_gold_chars\n",
    "            else:\n",
    "                file_levenshtein_error_rate = 0.0\n",
    "\n",
    "            # Final file-level Character Error Rate\n",
    "            if total_gold_chars > 0:\n",
    "                file_character_error_rate = 1 - (total_matched_chars / total_gold_chars)\n",
    "            else:\n",
    "                file_character_error_rate = 0.0\n",
    "\n",
    "            # Final Weighted Word Accuracy\n",
    "            if sum_length_weights > 0:\n",
    "                file_weighted_word_accuracy = sum_weighted_word_contrib / sum_length_weights\n",
    "            else:\n",
    "                file_weighted_word_accuracy = 0.0\n",
    "\n",
    "            # Sentence Accuracy (average)\n",
    "            if record_count > 0:\n",
    "                file_sentence_accuracy = sum_sentence_accuracy / record_count\n",
    "            else:\n",
    "                file_sentence_accuracy = 0.0\n",
    "\n",
    "            # NEW: file-level average (unweighted) word accuracy\n",
    "            if total_gold_words > 0:\n",
    "                file_average_word_accuracy = total_matched_words / total_gold_words\n",
    "            else:\n",
    "                file_average_word_accuracy = 0.0\n",
    "\n",
    "            # Write file summary\n",
    "            out_f.write(f\"--- Summary for file: {filename} ---\\n\")\n",
    "            out_f.write(f\"Total records processed: {record_count}\\n\\n\")\n",
    "            out_f.write(f\"Weighted Levenshtein Error Rate (File-level):  {file_levenshtein_error_rate:.4f}\\n\")\n",
    "            out_f.write(f\"Weighted Character Error Rate (File-level):    {file_character_error_rate:.4f}\\n\")\n",
    "            out_f.write(f\"Weighted Word Accuracy (File-level, k={k}):     {file_weighted_word_accuracy:.4f}\\n\")\n",
    "            out_f.write(f\"Average Sentence Accuracy (File-level):        {file_sentence_accuracy:.4f}\\n\")\n",
    "            out_f.write(f\"Average Word Accuracy (File-level, unweighted): {file_average_word_accuracy:.4f}\\n\\n\")\n",
    "\n",
    "            # NEW: file-level totals\n",
    "            out_f.write(f\"File-level totals:\\n\")\n",
    "            out_f.write(f\"  total_characters_in_gold_label: {total_gold_chars}\\n\")\n",
    "            out_f.write(f\"  total_matched_characters:       {total_matched_chars}\\n\")\n",
    "            out_f.write(f\"  total_words_in_gold_label:      {total_gold_words}\\n\")\n",
    "            out_f.write(f\"  total_matched_words:            {total_matched_words}\\n\")\n",
    "            out_f.write(\"==========================================\\n\\n\")\n",
    "\n",
    "        # Return a dictionary of file-level results (used for CSV)\n",
    "        return {\n",
    "            'filename': filename,\n",
    "            'model_name': fields.get('model_name', ''),\n",
    "            'shift': fields.get('shift', ''),\n",
    "            'prompt_type': fields.get('prompt_type', ''),\n",
    "            'temperature': fields.get('temperature', ''),\n",
    "            'max_token': fields.get('max_token', ''),\n",
    "            'levenshtein_error_rate': file_levenshtein_error_rate,\n",
    "            'character_error_rate': file_character_error_rate,\n",
    "            'weighted_word_accuracy': file_weighted_word_accuracy,\n",
    "            'sentence_accuracy': file_sentence_accuracy,\n",
    "            # Include the new average word accuracy in the CSV\n",
    "            'avg_word_accuracy': file_average_word_accuracy\n",
    "        }\n",
    "\n",
    "    def process_directory(self):\n",
    "        \"\"\"\n",
    "        Iterates over all .json files in the directory, processes each, \n",
    "        and accumulates final metrics for CSV output.\n",
    "        \"\"\"\n",
    "        for filename in os.listdir(self.directory):\n",
    "            if filename.endswith('.json'):\n",
    "                filepath = os.path.join(self.directory, filename)\n",
    "                filename_without_ext = filename[:-5]\n",
    "                \n",
    "                # Extract timestamp from filename to match with config\n",
    "                timestamp = self.extract_timestamp(filename_without_ext)\n",
    "                fields = self.config_data.get(timestamp)\n",
    "                \n",
    "                if not fields:\n",
    "                    logging.warning(\n",
    "                        f\"Timestamp '{timestamp}' from filename '{filename_without_ext}' \"\n",
    "                        f\"not found in config file {self.config_file}\"\n",
    "                    )\n",
    "                    continue\n",
    "\n",
    "                file_results = self.process_json_file(filepath, fields)\n",
    "                if file_results:\n",
    "                    self.file_level_results.append(file_results)\n",
    "\n",
    "    def write_csv_results(self):\n",
    "        \"\"\"\n",
    "        Writes the accumulated file-level metrics to a CSV file, including\n",
    "        Weighted Word Accuracy (k=2), Average Word Accuracy, etc.\n",
    "        \"\"\"\n",
    "        csv_file = self.config.csv_file_result\n",
    "\n",
    "        def shift_as_int(val):\n",
    "            try:\n",
    "                return int(val['shift'])\n",
    "            except ValueError:\n",
    "                return 999999  # fallback if not numeric\n",
    "\n",
    "        self.file_level_results.sort(key=lambda x: (x['model_name'], shift_as_int(x), x['prompt_type']))\n",
    "\n",
    "        with open(csv_file, mode='w', newline='', encoding='utf-8') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\n",
    "                'Filename', \n",
    "                'Model', \n",
    "                'Shift', \n",
    "                'Prompt Type', \n",
    "                'Temperature', \n",
    "                'Max Token',\n",
    "                'Levenshtein Error Rate (%)', \n",
    "                'Character Error Rate (%)',\n",
    "                'Weighted Word Accuracy (%)',\n",
    "                'Sentence Accuracy (%)',\n",
    "                'Average Word Accuracy (%)'\n",
    "            ])\n",
    "            for res in self.file_level_results:\n",
    "                writer.writerow([\n",
    "                    res['filename'],\n",
    "                    res['model_name'],\n",
    "                    res['shift'],\n",
    "                    res['prompt_type'],\n",
    "                    res['temperature'],\n",
    "                    res['max_token'],\n",
    "                    f\"{res['levenshtein_error_rate'] * 100:.2f}\",\n",
    "                    f\"{res['character_error_rate'] * 100:.2f}\",\n",
    "                    f\"{res['weighted_word_accuracy'] * 100:.2f}\",\n",
    "                    f\"{res['sentence_accuracy'] * 100:.2f}\",\n",
    "                    f\"{res['avg_word_accuracy'] * 100:.2f}\"\n",
    "                ])\n",
    "        logging.info(f\"CSV results written to '{csv_file}'\")\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Main entry point: processes the JSON files, then writes final CSV results.\n",
    "        \"\"\"\n",
    "        self.process_directory()\n",
    "        self.write_csv_results()\n",
    "        logging.info(f\"Processing finished.\\n\"\n",
    "                     f\"  - Detailed record-level results: '{self.config.output_details_file}'\\n\"\n",
    "                     f\"  - File-level summary CSV: '{self.config.csv_file_result}'\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    config = Config()\n",
    "    caesar_test = CaesarCipherTest(config)\n",
    "    caesar_test.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ecd2ce-2003-4a3d-8f6d-2a6947b12958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================\n",
    "# RANDOM TEXT INPUT\n",
    "# =======================\n",
    "\n",
    "import os\n",
    "import json\n",
    "import csv\n",
    "import logging\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from typing import Dict, Optional\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "\n",
    "class Config:\n",
    "    def __init__(self):\n",
    "        # Directory containing the JSON files\n",
    "        self.data_directory = './data/encoded/caesar-cipher/random/'\n",
    "        # Path to the configuration file\n",
    "        self.config_file_path = './caesar-cipher-experiments-log-random-text.txt'\n",
    "        # CSV output file for aggregated metrics\n",
    "        self.csv_file_result = 'caesar-cipher-random-text-benchmark-result.csv'\n",
    "        # Text file containing all details\n",
    "        self.output_details_file = 'caesar-cipher-random-text-benchmark-process.txt'\n",
    "\n",
    "class CaesarCipherTest:\n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config\n",
    "        self.directory = self.config.data_directory\n",
    "        self.config_file = self.config.config_file_path\n",
    "        # Parse config file once for metadata\n",
    "        self.config_data = self.parse_config_file()\n",
    "\n",
    "        # Exponent for weighting sequences by their word length\n",
    "        # (k=2 means longer sequences are squared in their influence)\n",
    "        self.word_weight_exponent = 2\n",
    "\n",
    "        # Accumulate final (file-level) results for the CSV\n",
    "        self.file_level_results = []\n",
    "        \n",
    "        # Clear or create the output details file at the start\n",
    "        with open(self.config.output_details_file, 'w', encoding='utf-8') as f:\n",
    "            f.write(\"Comprehensive operation details for random text results:\\n\\n\")\n",
    "\n",
    "    def parse_config_file(self) -> Dict[str, Dict[str, str]]:\n",
    "        config_data = {}\n",
    "        try:\n",
    "            with open(self.config_file, 'r') as f:\n",
    "                for line in f:\n",
    "                    line = line.strip()\n",
    "                    if line:\n",
    "                        timestamp = self.extract_timestamp(line)\n",
    "                        fields = self.parse_filename(line)\n",
    "                        config_data[timestamp] = fields\n",
    "        except FileNotFoundError:\n",
    "            logging.error(f\"Config file {self.config_file} not found.\")\n",
    "        return config_data\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_timestamp(filename: str) -> str:\n",
    "        \"\"\"\n",
    "        Example: 20230101_122345_some-other-stuff -> timestamp would be 20230101_122345\n",
    "        \"\"\"\n",
    "        parts = filename.split('_')\n",
    "        if len(parts) >= 2:\n",
    "            return f\"{parts[0]}_{parts[1]}\"\n",
    "        return parts[0]\n",
    "\n",
    "    @staticmethod\n",
    "    def parse_filename(filename: str) -> Dict[str, str]:\n",
    "        \"\"\"\n",
    "        A robust approach that handles both Llama-like (__0.01_64) \n",
    "        and Mistral-like (_0.01_64) suffixes.\n",
    "        \"\"\"\n",
    "        if filename.endswith('.json'):\n",
    "            filename = filename[:-5]\n",
    "\n",
    "        pattern = r'^(.*)_([\\d\\.]+)_(\\d+)$'\n",
    "        match = re.match(pattern, filename)\n",
    "        if match:\n",
    "            pre_model_info = match.group(1)\n",
    "            temperature   = match.group(2)\n",
    "            max_token     = match.group(3)\n",
    "        else:\n",
    "            pre_model_info = filename\n",
    "            temperature    = ''\n",
    "            max_token      = ''\n",
    "\n",
    "        pre_fields = pre_model_info.split('_')\n",
    "\n",
    "        date        = pre_fields[0] if len(pre_fields) > 0 else ''\n",
    "        time        = pre_fields[1] if len(pre_fields) > 1 else ''\n",
    "        samples     = pre_fields[2] if len(pre_fields) > 2 else ''\n",
    "        shift       = pre_fields[3] if len(pre_fields) > 3 else ''\n",
    "        prompt_type = '_'.join(pre_fields[4:6]) if len(pre_fields) > 5 else ''\n",
    "        method      = pre_fields[6] if len(pre_fields) > 6 else ''\n",
    "\n",
    "        shot_and_model_name_parts = pre_fields[7:]\n",
    "        shot_and_model_name       = '_'.join(shot_and_model_name_parts)\n",
    "\n",
    "        if '-' in shot_and_model_name:\n",
    "            shot, model_name = shot_and_model_name.split('-', 1)\n",
    "        else:\n",
    "            shot = ''\n",
    "            model_name = shot_and_model_name\n",
    "\n",
    "        if model_name.startswith('models--'):\n",
    "            model_name = model_name[len('models--'):]\n",
    "            model_parts = model_name.split('--')\n",
    "            model_name  = model_parts[-1]\n",
    "        model_name = model_name.rstrip('_')\n",
    "\n",
    "        return {\n",
    "            'date': date,\n",
    "            'time': time,\n",
    "            'samples': samples,\n",
    "            'shift': shift,\n",
    "            'prompt_type': prompt_type,\n",
    "            'method': method,\n",
    "            'shot': shot,\n",
    "            'model_name': model_name,\n",
    "            'temperature': temperature,\n",
    "            'max_token': max_token\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def levenshtein_distance(s1: str, s2: str) -> int:\n",
    "        \"\"\"\n",
    "        Compute the Levenshtein edit distance between two strings s1 and s2\n",
    "        (minimum number of single-character edits).\n",
    "        \"\"\"\n",
    "        if not s1:\n",
    "            return len(s2)\n",
    "        if not s2:\n",
    "            return len(s1)\n",
    "\n",
    "        len_s1 = len(s1)\n",
    "        len_s2 = len(s2)\n",
    "\n",
    "        dp = [[0] * (len_s2 + 1) for _ in range(len_s1 + 1)]\n",
    "\n",
    "        for i in range(len_s1 + 1):\n",
    "            dp[i][0] = i\n",
    "        for j in range(len_s2 + 1):\n",
    "            dp[0][j] = j\n",
    "\n",
    "        for i in range(1, len_s1 + 1):\n",
    "            for j in range(1, len_s2 + 1):\n",
    "                cost = 0 if s1[i-1] == s2[j-1] else 1\n",
    "                dp[i][j] = min(\n",
    "                    dp[i-1][j] + 1,       # deletion\n",
    "                    dp[i][j-1] + 1,       # insertion\n",
    "                    dp[i-1][j-1] + cost   # substitution\n",
    "                )\n",
    "\n",
    "        return dp[len_s1][len_s2]\n",
    "\n",
    "    def compute_per_record_metrics(self, cipher_text: str, gold_label: str) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Compute per-record metrics:\n",
    "          1) Levenshtein Error Rate: dist / len(gold_label)\n",
    "          2) Character Error Rate:   1 - (# matched chars / len(gold_label))\n",
    "          3) Word Accuracy (raw fraction for a single record)\n",
    "          4) Sentence Accuracy: 1.0 if exact match else 0.0\n",
    "        \"\"\"\n",
    "        gold_len = len(gold_label)\n",
    "        \n",
    "        # 1) Levenshtein Error Rate\n",
    "        if gold_len > 0:\n",
    "            dist = self.levenshtein_distance(cipher_text, gold_label)\n",
    "            levenshtein_error_rate = dist / gold_len\n",
    "            # Cap the Levenshtein Error Rate at 100 if it exceeds this threshold\n",
    "            if levenshtein_error_rate > 1:\n",
    "                levenshtein_error_rate = 1.0000\n",
    "                dist = gold_len\n",
    "        else:\n",
    "            dist = 0\n",
    "            levenshtein_error_rate = 0.0\n",
    "\n",
    "        # 2) Character Error Rate\n",
    "        matched_chars = 0\n",
    "        for i in range(gold_len):\n",
    "            if i < len(cipher_text) and cipher_text[i] == gold_label[i]:\n",
    "                matched_chars += 1\n",
    "\n",
    "        if gold_len > 0:\n",
    "            character_error_rate = 1 - (matched_chars / gold_len)\n",
    "        else:\n",
    "            character_error_rate = 0.0\n",
    "\n",
    "        # 3) Word Accuracy (unweighted, just per-record fraction)\n",
    "        gold_words = gold_label.split()\n",
    "        pred_words = cipher_text.split()\n",
    "        matched_words = sum(gw == pw for gw, pw in zip(gold_words, pred_words))\n",
    "        gold_words_len = len(gold_words)\n",
    "\n",
    "        if gold_words_len > 0:\n",
    "            word_accuracy = matched_words / gold_words_len\n",
    "        else:\n",
    "            word_accuracy = 0.0\n",
    "\n",
    "        # 4) Sentence Accuracy\n",
    "        sentence_accuracy = 1.0 if cipher_text == gold_label else 0.0\n",
    "\n",
    "        return {\n",
    "            'levenshtein_error_rate': levenshtein_error_rate,\n",
    "            'character_error_rate': character_error_rate,\n",
    "            'word_accuracy': word_accuracy,     # raw fraction for this record\n",
    "            'sentence_accuracy': sentence_accuracy,\n",
    "            # Additional for file-level weighting\n",
    "            'levenshtein_distance': dist,\n",
    "            'matched_chars': matched_chars,\n",
    "            'gold_length': gold_len,\n",
    "            'matched_words': matched_words,\n",
    "            'gold_words_len': gold_words_len\n",
    "        }\n",
    "\n",
    "    def process_json_file(self, filepath: str, fields: Dict[str, str]) -> Optional[Dict[str, float]]:\n",
    "        \"\"\"\n",
    "        Process a single JSON file:\n",
    "         - For each record: compute per-record metrics and log them.\n",
    "         - For file-level: \n",
    "             * Weighted word accuracy (using L^k).\n",
    "             * Weighted Levenshtein and Character Error Rate.\n",
    "             * Average Sentence Accuracy.\n",
    "             * NEW: total matched words vs. total gold words => file-level average word accuracy.\n",
    "        \"\"\"\n",
    "        filename = os.path.basename(filepath)\n",
    "        try:\n",
    "            with open(filepath, 'r', encoding='utf-8') as f:\n",
    "                content = f.read().strip()\n",
    "                if not content:\n",
    "                    logging.warning(f\"Skipping empty file: {filename}\")\n",
    "                    return None\n",
    "                data = json.loads(content)\n",
    "        except (json.JSONDecodeError, FileNotFoundError):\n",
    "            logging.error(f\"Error reading or decoding JSON in file: {filename}\")\n",
    "            return None\n",
    "\n",
    "        if not isinstance(data, list):\n",
    "            logging.error(f\"File {filename} does not contain a list of records.\")\n",
    "            return None\n",
    "\n",
    "        # Accumulators for file-level (weighted or otherwise)\n",
    "        total_levenshtein_distance = 0\n",
    "        total_matched_chars = 0\n",
    "        total_gold_chars = 0\n",
    "\n",
    "        # Weighted Word Accuracy accumulators\n",
    "        sum_weighted_word_contrib = 0.0\n",
    "        sum_length_weights = 0.0\n",
    "\n",
    "        # Sentence accuracy accumulators\n",
    "        sum_sentence_accuracy = 0.0\n",
    "        record_count = 0\n",
    "\n",
    "        # accumulators for average word accuracy\n",
    "        total_matched_words = 0\n",
    "        total_gold_words = 0\n",
    "\n",
    "        # Start logging to the details file\n",
    "        with open(self.config.output_details_file, 'a', encoding='utf-8') as out_f:\n",
    "            out_f.write(f\"=== Processing file: {filename} ===\\n\")\n",
    "            out_f.write(f\"Model name: {fields.get('model_name', '')}, Shift: {fields.get('shift', '')}, \"\n",
    "                        f\"Prompt Type: {fields.get('prompt_type', '')}, Temperature: {fields.get('temperature', '')}, \"\n",
    "                        f\"Max Token: {fields.get('max_token', '')}\\n\\n\")\n",
    "\n",
    "            # k exponent for weighting word accuracy\n",
    "            k = self.word_weight_exponent\n",
    "\n",
    "            # Process each record\n",
    "            for idx, record in enumerate(data, start=1):\n",
    "                cipher_text = record.get(\"cipher_text\", \"\").strip()\n",
    "                gold_label = record.get(\"gold_label\", \"\").strip()\n",
    "\n",
    "                if not cipher_text and not gold_label:\n",
    "                    continue\n",
    "\n",
    "                metrics = self.compute_per_record_metrics(cipher_text, gold_label)\n",
    "\n",
    "                # Basic record-level fraction\n",
    "                record_word_acc = metrics['word_accuracy']\n",
    "                L_i = metrics['gold_words_len']\n",
    "\n",
    "                # Weight factor = (L_i^k)\n",
    "                length_weight = (L_i ** k)\n",
    "                # Weighted contribution for word accuracy\n",
    "                weighted_contribution = length_weight * record_word_acc\n",
    "\n",
    "                # Accumulate for file-level\n",
    "                total_levenshtein_distance += metrics['levenshtein_distance']\n",
    "                total_matched_chars += metrics['matched_chars']\n",
    "                total_gold_chars += metrics['gold_length']\n",
    "\n",
    "                # Accumulate for average word accuracy\n",
    "                total_matched_words += metrics['matched_words']\n",
    "                total_gold_words += metrics['gold_words_len']\n",
    "\n",
    "                # Weighted Word Accuracy sums\n",
    "                sum_weighted_word_contrib += weighted_contribution\n",
    "                sum_length_weights += length_weight\n",
    "\n",
    "                sum_sentence_accuracy += metrics['sentence_accuracy']\n",
    "                record_count += 1\n",
    "\n",
    "                # Log per-record details\n",
    "                out_f.write(f\"Record #{idx}\\n\")\n",
    "                out_f.write(f\"  cipher_text: {cipher_text}\\n\")\n",
    "                out_f.write(f\"  gold_label:  {gold_label}\\n\")\n",
    "                out_f.write(f\"  Levenshtein Error Rate: {metrics['levenshtein_error_rate']:.4f}\\n\")\n",
    "                out_f.write(f\"  Character Error Rate:   {metrics['character_error_rate']:.4f}\\n\")\n",
    "                out_f.write(f\"  Word Accuracy (record, raw): {record_word_acc:.4f}\\n\")\n",
    "                out_f.write(f\"  Sentence Accuracy: {metrics['sentence_accuracy']:.4f}\\n\")\n",
    "\n",
    "                # print matched chars, matched words, gold chars, gold words\n",
    "                out_f.write(f\"  matched_characters: {metrics['matched_chars']}\\n\")\n",
    "                out_f.write(f\"  gold_characters:    {metrics['gold_length']}\\n\")\n",
    "                out_f.write(f\"  matched_words:      {metrics['matched_words']}\\n\")\n",
    "                out_f.write(f\"  gold_words_len:     {metrics['gold_words_len']}\\n\")\n",
    "\n",
    "                # Show the weighting details\n",
    "                out_f.write(f\"  Word length (L_i): {L_i},  k={k},  Weight factor = L_i^k = {length_weight}\\n\")\n",
    "                out_f.write(f\"  Weighted Word Contribution = {length_weight:.2f} * {record_word_acc:.4f} = {weighted_contribution:.4f}\\n\\n\")\n",
    "\n",
    "            # Final file-level Levenshtein Error Rate\n",
    "            if total_gold_chars > 0:\n",
    "                file_levenshtein_error_rate = total_levenshtein_distance / total_gold_chars\n",
    "            else:\n",
    "                file_levenshtein_error_rate = 0.0\n",
    "\n",
    "            # Final file-level Character Error Rate\n",
    "            if total_gold_chars > 0:\n",
    "                file_character_error_rate = 1 - (total_matched_chars / total_gold_chars)\n",
    "            else:\n",
    "                file_character_error_rate = 0.0\n",
    "\n",
    "            # Final Weighted Word Accuracy\n",
    "            if sum_length_weights > 0:\n",
    "                file_weighted_word_accuracy = sum_weighted_word_contrib / sum_length_weights\n",
    "            else:\n",
    "                file_weighted_word_accuracy = 0.0\n",
    "\n",
    "            # Sentence Accuracy (average)\n",
    "            if record_count > 0:\n",
    "                file_sentence_accuracy = sum_sentence_accuracy / record_count\n",
    "            else:\n",
    "                file_sentence_accuracy = 0.0\n",
    "\n",
    "            # NEW: file-level average (unweighted) word accuracy\n",
    "            if total_gold_words > 0:\n",
    "                file_average_word_accuracy = total_matched_words / total_gold_words\n",
    "            else:\n",
    "                file_average_word_accuracy = 0.0\n",
    "\n",
    "            # Write file summary\n",
    "            out_f.write(f\"--- Summary for file: {filename} ---\\n\")\n",
    "            out_f.write(f\"Total records processed: {record_count}\\n\\n\")\n",
    "            out_f.write(f\"Weighted Levenshtein Error Rate (File-level):  {file_levenshtein_error_rate:.4f}\\n\")\n",
    "            out_f.write(f\"Weighted Character Error Rate (File-level):    {file_character_error_rate:.4f}\\n\")\n",
    "            out_f.write(f\"Weighted Word Accuracy (File-level, k={k}):     {file_weighted_word_accuracy:.4f}\\n\")\n",
    "            out_f.write(f\"Average Sentence Accuracy (File-level):        {file_sentence_accuracy:.4f}\\n\")\n",
    "            out_f.write(f\"Average Word Accuracy (File-level, unweighted): {file_average_word_accuracy:.4f}\\n\\n\")\n",
    "\n",
    "            # NEW: file-level totals\n",
    "            out_f.write(f\"File-level totals:\\n\")\n",
    "            out_f.write(f\"  total_characters_in_gold_label: {total_gold_chars}\\n\")\n",
    "            out_f.write(f\"  total_matched_characters:       {total_matched_chars}\\n\")\n",
    "            out_f.write(f\"  total_words_in_gold_label:      {total_gold_words}\\n\")\n",
    "            out_f.write(f\"  total_matched_words:            {total_matched_words}\\n\")\n",
    "            out_f.write(\"==========================================\\n\\n\")\n",
    "\n",
    "        # Return a dictionary of file-level results (used for CSV)\n",
    "        return {\n",
    "            'filename': filename,\n",
    "            'model_name': fields.get('model_name', ''),\n",
    "            'shift': fields.get('shift', ''),\n",
    "            'prompt_type': fields.get('prompt_type', ''),\n",
    "            'temperature': fields.get('temperature', ''),\n",
    "            'max_token': fields.get('max_token', ''),\n",
    "            'levenshtein_error_rate': file_levenshtein_error_rate,\n",
    "            'character_error_rate': file_character_error_rate,\n",
    "            'weighted_word_accuracy': file_weighted_word_accuracy,\n",
    "            'sentence_accuracy': file_sentence_accuracy,\n",
    "            # Include the new average word accuracy in the CSV\n",
    "            'avg_word_accuracy': file_average_word_accuracy\n",
    "        }\n",
    "\n",
    "    def process_directory(self):\n",
    "        \"\"\"\n",
    "        Iterates over all .json files in the directory, processes each, \n",
    "        and accumulates final metrics for CSV output.\n",
    "        \"\"\"\n",
    "        for filename in os.listdir(self.directory):\n",
    "            if filename.endswith('.json'):\n",
    "                filepath = os.path.join(self.directory, filename)\n",
    "                filename_without_ext = filename[:-5]\n",
    "                \n",
    "                # Extract timestamp from filename to match with config\n",
    "                timestamp = self.extract_timestamp(filename_without_ext)\n",
    "                fields = self.config_data.get(timestamp)\n",
    "                \n",
    "                if not fields:\n",
    "                    logging.warning(\n",
    "                        f\"Timestamp '{timestamp}' from filename '{filename_without_ext}' \"\n",
    "                        f\"not found in config file {self.config_file}\"\n",
    "                    )\n",
    "                    continue\n",
    "\n",
    "                file_results = self.process_json_file(filepath, fields)\n",
    "                if file_results:\n",
    "                    self.file_level_results.append(file_results)\n",
    "\n",
    "    def write_csv_results(self):\n",
    "        \"\"\"\n",
    "        Writes the accumulated file-level metrics to a CSV file, including\n",
    "        Weighted Word Accuracy (k=2), Average Word Accuracy, etc.\n",
    "        \"\"\"\n",
    "        csv_file = self.config.csv_file_result\n",
    "\n",
    "        def shift_as_int(val):\n",
    "            try:\n",
    "                return int(val['shift'])\n",
    "            except ValueError:\n",
    "                return 999999  # fallback if not numeric\n",
    "\n",
    "        self.file_level_results.sort(key=lambda x: (x['model_name'], shift_as_int(x), x['prompt_type']))\n",
    "\n",
    "        with open(csv_file, mode='w', newline='', encoding='utf-8') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\n",
    "                'Filename', \n",
    "                'Model', \n",
    "                'Shift', \n",
    "                'Prompt Type', \n",
    "                'Temperature', \n",
    "                'Max Token',\n",
    "                'Levenshtein Error Rate (%)', \n",
    "                'Character Error Rate (%)',\n",
    "                'Weighted Word Accuracy (%)',\n",
    "                'Sentence Accuracy (%)',\n",
    "                'Average Word Accuracy (%)'\n",
    "            ])\n",
    "            for res in self.file_level_results:\n",
    "                writer.writerow([\n",
    "                    res['filename'],\n",
    "                    res['model_name'],\n",
    "                    res['shift'],\n",
    "                    res['prompt_type'],\n",
    "                    res['temperature'],\n",
    "                    res['max_token'],\n",
    "                    f\"{res['levenshtein_error_rate'] * 100:.2f}\",\n",
    "                    f\"{res['character_error_rate'] * 100:.2f}\",\n",
    "                    f\"{res['weighted_word_accuracy'] * 100:.2f}\",\n",
    "                    f\"{res['sentence_accuracy'] * 100:.2f}\",\n",
    "                    f\"{res['avg_word_accuracy'] * 100:.2f}\"\n",
    "                ])\n",
    "        logging.info(f\"CSV results written to '{csv_file}'\")\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Main entry point: processes the JSON files, then writes final CSV results.\n",
    "        \"\"\"\n",
    "        self.process_directory()\n",
    "        self.write_csv_results()\n",
    "        logging.info(f\"Processing finished.\\n\"\n",
    "                     f\"  - Detailed record-level results: '{self.config.output_details_file}'\\n\"\n",
    "                     f\"  - File-level summary CSV: '{self.config.csv_file_result}'\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    config = Config()\n",
    "    caesar_test = CaesarCipherTest(config)\n",
    "    caesar_test.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06da6b33-b6b7-4611-8d74-8d553b98d88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================\n",
    "# GREEK TEXT INPUT\n",
    "# =======================\n",
    "\n",
    "import os\n",
    "import json\n",
    "import csv\n",
    "import logging\n",
    "import re\n",
    "import unicodedata\n",
    "from typing import Dict, Optional\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "\n",
    "def normalize_greek_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Normalize Greek text to a consistent Unicode form (e.g., NFC).\n",
    "    This helps ensure that any accented Greek letters and their\n",
    "    combining marks are treated uniformly.\n",
    "\n",
    "    If your Caesar logic requires ignoring diacritics altogether,\n",
    "    you can modify this function to strip them.\n",
    "    \"\"\"\n",
    "    # Normalizing to NFC is usually sufficient for comparing Greek text.\n",
    "    return unicodedata.normalize(\"NFC\", text)\n",
    "\n",
    "class Config:\n",
    "    def __init__(self):\n",
    "        # Directory containing the JSON files with Greek Caesar-cipher data\n",
    "        self.data_directory = './data/encoded/caesar-cipher/greek/'\n",
    "        # Path to the configuration file\n",
    "        self.config_file_path = './caesar-cipher-experiments-log-greek-text.txt'\n",
    "        # CSV output file for aggregated metrics\n",
    "        self.csv_file_result = 'caesar-cipher-greek-text-benchmark-result.csv'\n",
    "        # Text file containing all details\n",
    "        self.output_details_file = 'caesar-cipher-greek-text-benchmark-process.txt'\n",
    "\n",
    "class CaesarCipherTest:\n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config\n",
    "        self.directory = self.config.data_directory\n",
    "        self.config_file = self.config.config_file_path\n",
    "\n",
    "        # Parse config file once for metadata\n",
    "        self.config_data = self.parse_config_file()\n",
    "\n",
    "        # Exponent for weighting sequences by their word length\n",
    "        # (k=2 means longer sequences have higher influence)\n",
    "        self.word_weight_exponent = 2\n",
    "\n",
    "        # Accumulate final (file-level) results for the CSV\n",
    "        self.file_level_results = []\n",
    "        \n",
    "        # Clear or create the output details file at the start\n",
    "        with open(self.config.output_details_file, 'w', encoding='utf-8') as f:\n",
    "            f.write(\"Comprehensive operation details for Greek text results:\\n\\n\")\n",
    "\n",
    "    def parse_config_file(self) -> Dict[str, Dict[str, str]]:\n",
    "        config_data = {}\n",
    "        try:\n",
    "            with open(self.config_file, 'r', encoding='utf-8') as f:\n",
    "                for line in f:\n",
    "                    line = line.strip()\n",
    "                    if line:\n",
    "                        timestamp = self.extract_timestamp(line)\n",
    "                        fields = self.parse_filename(line)\n",
    "                        config_data[timestamp] = fields\n",
    "        except FileNotFoundError:\n",
    "            logging.error(f\"Config file {self.config_file} not found.\")\n",
    "        return config_data\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_timestamp(filename: str) -> str:\n",
    "        \"\"\"\n",
    "        Example: 20230101_122345_some-other-stuff -> timestamp would be 20230101_122345\n",
    "        \"\"\"\n",
    "        parts = filename.split('_')\n",
    "        if len(parts) >= 2:\n",
    "            return f\"{parts[0]}_{parts[1]}\"\n",
    "        return parts[0]\n",
    "\n",
    "    @staticmethod\n",
    "    def parse_filename(filename: str) -> Dict[str, str]:\n",
    "        \"\"\"\n",
    "        A robust approach that handles both Llama-like (__0.01_64) \n",
    "        and Mistral-like (_0.01_64) suffixes.\n",
    "        \"\"\"\n",
    "        if filename.endswith('.json'):\n",
    "            filename = filename[:-5]\n",
    "\n",
    "        pattern = r'^(.*)_([\\d\\.]+)_(\\d+)$'\n",
    "        match = re.match(pattern, filename)\n",
    "        if match:\n",
    "            pre_model_info = match.group(1)\n",
    "            temperature   = match.group(2)\n",
    "            max_token     = match.group(3)\n",
    "        else:\n",
    "            pre_model_info = filename\n",
    "            temperature    = ''\n",
    "            max_token      = ''\n",
    "\n",
    "        pre_fields = pre_model_info.split('_')\n",
    "\n",
    "        date        = pre_fields[0] if len(pre_fields) > 0 else ''\n",
    "        time        = pre_fields[1] if len(pre_fields) > 1 else ''\n",
    "        samples     = pre_fields[2] if len(pre_fields) > 2 else ''\n",
    "        shift       = pre_fields[3] if len(pre_fields) > 3 else ''\n",
    "        prompt_type = '_'.join(pre_fields[4:6]) if len(pre_fields) > 5 else ''\n",
    "        method      = pre_fields[6] if len(pre_fields) > 6 else ''\n",
    "\n",
    "        shot_and_model_name_parts = pre_fields[7:]\n",
    "        shot_and_model_name       = '_'.join(shot_and_model_name_parts)\n",
    "\n",
    "        if '-' in shot_and_model_name:\n",
    "            shot, model_name = shot_and_model_name.split('-', 1)\n",
    "        else:\n",
    "            shot = ''\n",
    "            model_name = shot_and_model_name\n",
    "\n",
    "        if model_name.startswith('models--'):\n",
    "            model_name = model_name[len('models--'):]\n",
    "            model_parts = model_name.split('--')\n",
    "            model_name  = model_parts[-1]\n",
    "        model_name = model_name.rstrip('_')\n",
    "\n",
    "        return {\n",
    "            'date': date,\n",
    "            'time': time,\n",
    "            'samples': samples,\n",
    "            'shift': shift,\n",
    "            'prompt_type': prompt_type,\n",
    "            'method': method,\n",
    "            'shot': shot,\n",
    "            'model_name': model_name,\n",
    "            'temperature': temperature,\n",
    "            'max_token': max_token\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def levenshtein_distance(s1: str, s2: str) -> int:\n",
    "        \"\"\"\n",
    "        Compute the Levenshtein edit distance between two strings s1 and s2\n",
    "        (minimum number of single-character edits).\n",
    "        \"\"\"\n",
    "        if not s1:\n",
    "            return len(s2)\n",
    "        if not s2:\n",
    "            return len(s1)\n",
    "\n",
    "        len_s1 = len(s1)\n",
    "        len_s2 = len(s2)\n",
    "\n",
    "        dp = [[0] * (len_s2 + 1) for _ in range(len_s1 + 1)]\n",
    "\n",
    "        for i in range(len_s1 + 1):\n",
    "            dp[i][0] = i\n",
    "        for j in range(len_s2 + 1):\n",
    "            dp[0][j] = j\n",
    "\n",
    "        for i in range(1, len_s1 + 1):\n",
    "            for j in range(1, len_s2 + 1):\n",
    "                cost = 0 if s1[i-1] == s2[j-1] else 1\n",
    "                dp[i][j] = min(\n",
    "                    dp[i-1][j] + 1,       # deletion\n",
    "                    dp[i][j-1] + 1,       # insertion\n",
    "                    dp[i-1][j-1] + cost   # substitution\n",
    "                )\n",
    "\n",
    "        return dp[len_s1][len_s2]\n",
    "\n",
    "    def compute_per_record_metrics(self, cipher_text: str, gold_label: str) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Compute per-record metrics:\n",
    "          1) Levenshtein Error Rate: dist / len(gold_label)\n",
    "          2) Character Error Rate:   1 - (# matched chars / len(gold_label))\n",
    "          3) Word Accuracy (raw fraction for a single record)\n",
    "          4) Sentence Accuracy: 1.0 if exact match else 0.0\n",
    "        \"\"\"\n",
    "\n",
    "        # Normalize both strings so that diacritics are handled consistently.\n",
    "        cipher_text = normalize_greek_text(cipher_text)\n",
    "        gold_label  = normalize_greek_text(gold_label)\n",
    "\n",
    "        gold_len = len(gold_label)\n",
    "        \n",
    "        # 1) Levenshtein Error Rate\n",
    "        if gold_len > 0:\n",
    "            dist = self.levenshtein_distance(cipher_text, gold_label)\n",
    "            levenshtein_error_rate = dist / gold_len\n",
    "            # Cap the Levenshtein Error Rate at 100 if it exceeds this threshold\n",
    "            if levenshtein_error_rate > 1:\n",
    "                levenshtein_error_rate = 1.0000\n",
    "                dist = gold_len\n",
    "        else:\n",
    "            dist = 0\n",
    "            levenshtein_error_rate = 0.0\n",
    "\n",
    "        # 2) Character Error Rate\n",
    "        matched_chars = 0\n",
    "        for i in range(gold_len):\n",
    "            if i < len(cipher_text) and cipher_text[i] == gold_label[i]:\n",
    "                matched_chars += 1\n",
    "\n",
    "        if gold_len > 0:\n",
    "            character_error_rate = 1 - (matched_chars / gold_len)\n",
    "        else:\n",
    "            character_error_rate = 0.0\n",
    "\n",
    "        # 3) Word Accuracy (unweighted, just per-record fraction)\n",
    "        gold_words = gold_label.split()\n",
    "        pred_words = cipher_text.split()\n",
    "        matched_words = sum(gw == pw for gw, pw in zip(gold_words, pred_words))\n",
    "        gold_words_len = len(gold_words)\n",
    "\n",
    "        if gold_words_len > 0:\n",
    "            word_accuracy = matched_words / gold_words_len\n",
    "        else:\n",
    "            word_accuracy = 0.0\n",
    "\n",
    "        # 4) Sentence Accuracy\n",
    "        sentence_accuracy = 1.0 if cipher_text == gold_label else 0.0\n",
    "\n",
    "        return {\n",
    "            'levenshtein_error_rate': levenshtein_error_rate,\n",
    "            'character_error_rate': character_error_rate,\n",
    "            'word_accuracy': word_accuracy,     # raw fraction for this record\n",
    "            'sentence_accuracy': sentence_accuracy,\n",
    "            # Additional for file-level weighting\n",
    "            'levenshtein_distance': dist,\n",
    "            'matched_chars': matched_chars,\n",
    "            'gold_length': gold_len,\n",
    "            'matched_words': matched_words,\n",
    "            'gold_words_len': gold_words_len\n",
    "        }\n",
    "\n",
    "    def process_json_file(self, filepath: str, fields: Dict[str, str]) -> Optional[Dict[str, float]]:\n",
    "        \"\"\"\n",
    "        Process a single JSON file containing Greek Caesar-cipher data:\n",
    "         - For each record: compute per-record metrics and log them.\n",
    "         - For file-level: \n",
    "             * Weighted word accuracy (using L^k).\n",
    "             * Weighted Levenshtein and Character Error Rate.\n",
    "             * Average Sentence Accuracy.\n",
    "             * total matched words vs. total gold words => file-level average word accuracy.\n",
    "        \"\"\"\n",
    "        filename = os.path.basename(filepath)\n",
    "        try:\n",
    "            with open(filepath, 'r', encoding='utf-8') as f:\n",
    "                content = f.read().strip()\n",
    "                if not content:\n",
    "                    logging.warning(f\"Skipping empty file: {filename}\")\n",
    "                    return None\n",
    "                data = json.loads(content)\n",
    "        except (json.JSONDecodeError, FileNotFoundError):\n",
    "            logging.error(f\"Error reading or decoding JSON in file: {filename}\")\n",
    "            return None\n",
    "\n",
    "        if not isinstance(data, list):\n",
    "            logging.error(f\"File {filename} does not contain a list of records.\")\n",
    "            return None\n",
    "\n",
    "        # Accumulators for file-level (weighted or otherwise)\n",
    "        total_levenshtein_distance = 0\n",
    "        total_matched_chars = 0\n",
    "        total_gold_chars = 0\n",
    "\n",
    "        # Weighted Word Accuracy accumulators\n",
    "        sum_weighted_word_contrib = 0.0\n",
    "        sum_length_weights = 0.0\n",
    "\n",
    "        # Sentence accuracy accumulators\n",
    "        sum_sentence_accuracy = 0.0\n",
    "        record_count = 0\n",
    "\n",
    "        # Accumulators for average word accuracy\n",
    "        total_matched_words = 0\n",
    "        total_gold_words = 0\n",
    "\n",
    "        # Start logging to the details file\n",
    "        with open(self.config.output_details_file, 'a', encoding='utf-8') as out_f:\n",
    "            out_f.write(f\"=== Processing file: {filename} ===\\n\")\n",
    "            out_f.write(f\"Model name: {fields.get('model_name', '')}, Shift: {fields.get('shift', '')}, \"\n",
    "                        f\"Prompt Type: {fields.get('prompt_type', '')}, Temperature: {fields.get('temperature', '')}, \"\n",
    "                        f\"Max Token: {fields.get('max_token', '')}\\n\\n\")\n",
    "\n",
    "            # k exponent for weighting word accuracy\n",
    "            k = self.word_weight_exponent\n",
    "\n",
    "            # Process each record\n",
    "            for idx, record in enumerate(data, start=1):\n",
    "                # Normalize inputs for Greek\n",
    "                cipher_text = normalize_greek_text(record.get(\"cipher_text\", \"\").strip())\n",
    "                gold_label  = normalize_greek_text(record.get(\"gold_label\", \"\").strip())\n",
    "\n",
    "                if not cipher_text and not gold_label:\n",
    "                    continue\n",
    "\n",
    "                metrics = self.compute_per_record_metrics(cipher_text, gold_label)\n",
    "\n",
    "                # Basic record-level fraction\n",
    "                record_word_acc = metrics['word_accuracy']\n",
    "                L_i = metrics['gold_words_len']\n",
    "\n",
    "                # Weight factor = (L_i ** k)\n",
    "                length_weight = (L_i ** k)\n",
    "                # Weighted contribution for word accuracy\n",
    "                weighted_contribution = length_weight * record_word_acc\n",
    "\n",
    "                # Accumulate for file-level\n",
    "                total_levenshtein_distance += metrics['levenshtein_distance']\n",
    "                total_matched_chars += metrics['matched_chars']\n",
    "                total_gold_chars += metrics['gold_length']\n",
    "\n",
    "                # Accumulate for average word accuracy\n",
    "                total_matched_words += metrics['matched_words']\n",
    "                total_gold_words += metrics['gold_words_len']\n",
    "\n",
    "                # Weighted Word Accuracy sums\n",
    "                sum_weighted_word_contrib += weighted_contribution\n",
    "                sum_length_weights += length_weight\n",
    "\n",
    "                sum_sentence_accuracy += metrics['sentence_accuracy']\n",
    "                record_count += 1\n",
    "\n",
    "                # Log per-record details\n",
    "                out_f.write(f\"Record #{idx}\\n\")\n",
    "                out_f.write(f\"  cipher_text: {cipher_text}\\n\")\n",
    "                out_f.write(f\"  gold_label:  {gold_label}\\n\")\n",
    "                out_f.write(f\"  Levenshtein Error Rate: {metrics['levenshtein_error_rate']:.4f}\\n\")\n",
    "                out_f.write(f\"  Character Error Rate:   {metrics['character_error_rate']:.4f}\\n\")\n",
    "                out_f.write(f\"  Word Accuracy (record, raw): {record_word_acc:.4f}\\n\")\n",
    "                out_f.write(f\"  Sentence Accuracy: {metrics['sentence_accuracy']:.4f}\\n\")\n",
    "\n",
    "                out_f.write(f\"  matched_characters: {metrics['matched_chars']}\\n\")\n",
    "                out_f.write(f\"  gold_characters:    {metrics['gold_length']}\\n\")\n",
    "                out_f.write(f\"  matched_words:      {metrics['matched_words']}\\n\")\n",
    "                out_f.write(f\"  gold_words_len:     {metrics['gold_words_len']}\\n\")\n",
    "\n",
    "                # Show the weighting details\n",
    "                out_f.write(f\"  Word length (L_i): {L_i},  k={k},  Weight factor = L_i^k = {length_weight}\\n\")\n",
    "                out_f.write(f\"  Weighted Word Contribution = {length_weight:.2f} * {record_word_acc:.4f} = {weighted_contribution:.4f}\\n\\n\")\n",
    "\n",
    "            # Final file-level Levenshtein Error Rate\n",
    "            if total_gold_chars > 0:\n",
    "                file_levenshtein_error_rate = total_levenshtein_distance / total_gold_chars\n",
    "            else:\n",
    "                file_levenshtein_error_rate = 0.0\n",
    "\n",
    "            # Final file-level Character Error Rate\n",
    "            if total_gold_chars > 0:\n",
    "                file_character_error_rate = 1 - (total_matched_chars / total_gold_chars)\n",
    "            else:\n",
    "                file_character_error_rate = 0.0\n",
    "\n",
    "            # Final Weighted Word Accuracy\n",
    "            if sum_length_weights > 0:\n",
    "                file_weighted_word_accuracy = sum_weighted_word_contrib / sum_length_weights\n",
    "            else:\n",
    "                file_weighted_word_accuracy = 0.0\n",
    "\n",
    "            # Sentence Accuracy (average)\n",
    "            if record_count > 0:\n",
    "                file_sentence_accuracy = sum_sentence_accuracy / record_count\n",
    "            else:\n",
    "                file_sentence_accuracy = 0.0\n",
    "\n",
    "            # File-level average (unweighted) word accuracy\n",
    "            if total_gold_words > 0:\n",
    "                file_average_word_accuracy = total_matched_words / total_gold_words\n",
    "            else:\n",
    "                file_average_word_accuracy = 0.0\n",
    "\n",
    "            # Write file summary\n",
    "            out_f.write(f\"--- Summary for file: {filename} ---\\n\")\n",
    "            out_f.write(f\"Total records processed: {record_count}\\n\\n\")\n",
    "            out_f.write(f\"Weighted Levenshtein Error Rate (File-level):  {file_levenshtein_error_rate:.4f}\\n\")\n",
    "            out_f.write(f\"Weighted Character Error Rate (File-level):    {file_character_error_rate:.4f}\\n\")\n",
    "            out_f.write(f\"Weighted Word Accuracy (File-level, k={k}):     {file_weighted_word_accuracy:.4f}\\n\")\n",
    "            out_f.write(f\"Average Sentence Accuracy (File-level):        {file_sentence_accuracy:.4f}\\n\")\n",
    "            out_f.write(f\"Average Word Accuracy (File-level, unweighted): {file_average_word_accuracy:.4f}\\n\\n\")\n",
    "\n",
    "            out_f.write(f\"File-level totals:\\n\")\n",
    "            out_f.write(f\"  total_characters_in_gold_label: {total_gold_chars}\\n\")\n",
    "            out_f.write(f\"  total_matched_characters:       {total_matched_chars}\\n\")\n",
    "            out_f.write(f\"  total_words_in_gold_label:      {total_gold_words}\\n\")\n",
    "            out_f.write(f\"  total_matched_words:            {total_matched_words}\\n\")\n",
    "            out_f.write(\"==========================================\\n\\n\")\n",
    "\n",
    "        # Return a dictionary of file-level results (used for CSV)\n",
    "        return {\n",
    "            'filename': filename,\n",
    "            'model_name': fields.get('model_name', ''),\n",
    "            'shift': fields.get('shift', ''),\n",
    "            'prompt_type': fields.get('prompt_type', ''),\n",
    "            'temperature': fields.get('temperature', ''),\n",
    "            'max_token': fields.get('max_token', ''),\n",
    "            'levenshtein_error_rate': file_levenshtein_error_rate,\n",
    "            'character_error_rate': file_character_error_rate,\n",
    "            'weighted_word_accuracy': file_weighted_word_accuracy,\n",
    "            'sentence_accuracy': file_sentence_accuracy,\n",
    "            'avg_word_accuracy': file_average_word_accuracy\n",
    "        }\n",
    "\n",
    "    def process_directory(self):\n",
    "        \"\"\"\n",
    "        Iterates over all .json files in the directory, processes each, \n",
    "        and accumulates final metrics for CSV output.\n",
    "        \"\"\"\n",
    "        for filename in os.listdir(self.directory):\n",
    "            if filename.endswith('.json'):\n",
    "                filepath = os.path.join(self.directory, filename)\n",
    "                filename_without_ext = filename[:-5]\n",
    "                \n",
    "                # Extract timestamp from filename to match with config\n",
    "                timestamp = self.extract_timestamp(filename_without_ext)\n",
    "                fields = self.config_data.get(timestamp)\n",
    "                \n",
    "                if not fields:\n",
    "                    logging.warning(\n",
    "                        f\"Timestamp '{timestamp}' from filename '{filename_without_ext}' \"\n",
    "                        f\"not found in config file {self.config_file}\"\n",
    "                    )\n",
    "                    continue\n",
    "\n",
    "                file_results = self.process_json_file(filepath, fields)\n",
    "                if file_results:\n",
    "                    self.file_level_results.append(file_results)\n",
    "\n",
    "    def write_csv_results(self):\n",
    "        \"\"\"\n",
    "        Writes the accumulated file-level metrics to a CSV file, including\n",
    "        Weighted Word Accuracy (k=2), Average Word Accuracy, etc.\n",
    "        \"\"\"\n",
    "        csv_file = self.config.csv_file_result\n",
    "\n",
    "        def shift_as_int(val):\n",
    "            try:\n",
    "                return int(val['shift'])\n",
    "            except ValueError:\n",
    "                return 999999  # fallback if not numeric\n",
    "\n",
    "        self.file_level_results.sort(key=lambda x: (x['model_name'], shift_as_int(x), x['prompt_type']))\n",
    "\n",
    "        with open(csv_file, mode='w', newline='', encoding='utf-8') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\n",
    "                'Filename', \n",
    "                'Model', \n",
    "                'Shift', \n",
    "                'Prompt Type', \n",
    "                'Temperature', \n",
    "                'Max Token',\n",
    "                'Levenshtein Error Rate (%)', \n",
    "                'Character Error Rate (%)',\n",
    "                'Weighted Word Accuracy (%)',\n",
    "                'Sentence Accuracy (%)',\n",
    "                'Average Word Accuracy (%)'\n",
    "            ])\n",
    "            for res in self.file_level_results:\n",
    "                writer.writerow([\n",
    "                    res['filename'],\n",
    "                    res['model_name'],\n",
    "                    res['shift'],\n",
    "                    res['prompt_type'],\n",
    "                    res['temperature'],\n",
    "                    res['max_token'],\n",
    "                    f\"{res['levenshtein_error_rate'] * 100:.2f}\",\n",
    "                    f\"{res['character_error_rate'] * 100:.2f}\",\n",
    "                    f\"{res['weighted_word_accuracy'] * 100:.2f}\",\n",
    "                    f\"{res['sentence_accuracy'] * 100:.2f}\",\n",
    "                    f\"{res['avg_word_accuracy'] * 100:.2f}\"\n",
    "                ])\n",
    "        logging.info(f\"CSV results written to '{csv_file}'\")\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Main entry point: processes the JSON files, then writes final CSV results.\n",
    "        \"\"\"\n",
    "        self.process_directory()\n",
    "        self.write_csv_results()\n",
    "        logging.info(f\"Processing finished.\\n\"\n",
    "                     f\"  - Detailed record-level results: '{self.config.output_details_file}'\\n\"\n",
    "                     f\"  - File-level summary CSV: '{self.config.csv_file_result}'\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    config = Config()\n",
    "    caesar_test = CaesarCipherTest(config)\n",
    "    caesar_test.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badb2e53-45b0-44a5-a9aa-fe97753603ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================\n",
    "# VIGENERE - NATURAL TEXT INPUT\n",
    "# =======================\n",
    "\n",
    "\n",
    "import os\n",
    "import json\n",
    "import csv\n",
    "import logging\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from typing import Dict, Optional\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "\n",
    "class Config:\n",
    "    def __init__(self):\n",
    "        # Directory containing the JSON files\n",
    "        self.data_directory = './data/encoded/vigenere-cipher/'\n",
    "        # Path to the configuration file\n",
    "        self.config_file_path = './vigenere-cipher-experiments-log.txt'\n",
    "        # CSV output file for aggregated metrics\n",
    "        self.csv_file_result = 'vigenere-cipher-natural-text-benchmark-result.csv'\n",
    "        # Text file containing all details\n",
    "        self.output_details_file = 'vigenere-cipher-natural-text-benchmark-process.txt'\n",
    "\n",
    "class CaesarCipherTest:\n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config\n",
    "        self.directory = self.config.data_directory\n",
    "        self.config_file = self.config.config_file_path\n",
    "        # Parse config file once for metadata\n",
    "        self.config_data = self.parse_config_file()\n",
    "\n",
    "        # Exponent for weighting sequences by their word length\n",
    "        # (k=2 means longer sequences are squared in their influence)\n",
    "        self.word_weight_exponent = 2\n",
    "\n",
    "        # Accumulate final (file-level) results for the CSV\n",
    "        self.file_level_results = []\n",
    "        \n",
    "        # Clear or create the output details file at the start\n",
    "        with open(self.config.output_details_file, 'w', encoding='utf-8') as f:\n",
    "            f.write(\"Comprehensive operation details for random text results:\\n\\n\")\n",
    "\n",
    "    def parse_config_file(self) -> Dict[str, Dict[str, str]]:\n",
    "        config_data = {}\n",
    "        try:\n",
    "            with open(self.config_file, 'r') as f:\n",
    "                for line in f:\n",
    "                    line = line.strip()\n",
    "                    if line:\n",
    "                        timestamp = self.extract_timestamp(line)\n",
    "                        fields = self.parse_filename(line)\n",
    "                        config_data[timestamp] = fields\n",
    "        except FileNotFoundError:\n",
    "            logging.error(f\"Config file {self.config_file} not found.\")\n",
    "        return config_data\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_timestamp(filename: str) -> str:\n",
    "        \"\"\"\n",
    "        Example: 20230101_122345_some-other-stuff -> timestamp would be 20230101_122345\n",
    "        \"\"\"\n",
    "        parts = filename.split('_')\n",
    "        if len(parts) >= 2:\n",
    "            return f\"{parts[0]}_{parts[1]}\"\n",
    "        return parts[0]\n",
    "\n",
    "    @staticmethod\n",
    "    def parse_filename(filename: str) -> Dict[str, str]:\n",
    "        \"\"\"\n",
    "        A robust approach that handles both Llama-like (__0.01_64) \n",
    "        and Mistral-like (_0.01_64) suffixes.\n",
    "        \"\"\"\n",
    "        if filename.endswith('.json'):\n",
    "            filename = filename[:-5]\n",
    "\n",
    "        pattern = r'^(.*)_([\\d\\.]+)_(\\d+)$'\n",
    "        match = re.match(pattern, filename)\n",
    "        if match:\n",
    "            pre_model_info = match.group(1)\n",
    "            temperature   = match.group(2)\n",
    "            max_token     = match.group(3)\n",
    "        else:\n",
    "            pre_model_info = filename\n",
    "            temperature    = ''\n",
    "            max_token      = ''\n",
    "\n",
    "        pre_fields = pre_model_info.split('_')\n",
    "\n",
    "        date        = pre_fields[0] if len(pre_fields) > 0 else ''\n",
    "        time        = pre_fields[1] if len(pre_fields) > 1 else ''\n",
    "        samples     = pre_fields[2] if len(pre_fields) > 2 else ''\n",
    "        shift       = pre_fields[3] if len(pre_fields) > 3 else ''\n",
    "        prompt_type = '_'.join(pre_fields[4:6]) if len(pre_fields) > 5 else ''\n",
    "        method      = pre_fields[6] if len(pre_fields) > 6 else ''\n",
    "\n",
    "        shot_and_model_name_parts = pre_fields[7:]\n",
    "        shot_and_model_name       = '_'.join(shot_and_model_name_parts)\n",
    "\n",
    "        if '-' in shot_and_model_name:\n",
    "            shot, model_name = shot_and_model_name.split('-', 1)\n",
    "        else:\n",
    "            shot = ''\n",
    "            model_name = shot_and_model_name\n",
    "\n",
    "        if model_name.startswith('models--'):\n",
    "            model_name = model_name[len('models--'):]\n",
    "            model_parts = model_name.split('--')\n",
    "            model_name  = model_parts[-1]\n",
    "        model_name = model_name.rstrip('_')\n",
    "\n",
    "        return {\n",
    "            'date': date,\n",
    "            'time': time,\n",
    "            'samples': samples,\n",
    "            'shift': shift,\n",
    "            'prompt_type': prompt_type,\n",
    "            'method': method,\n",
    "            'shot': shot,\n",
    "            'model_name': model_name,\n",
    "            'temperature': temperature,\n",
    "            'max_token': max_token\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def levenshtein_distance(s1: str, s2: str) -> int:\n",
    "        \"\"\"\n",
    "        Compute the Levenshtein edit distance between two strings s1 and s2\n",
    "        (minimum number of single-character edits).\n",
    "        \"\"\"\n",
    "        if not s1:\n",
    "            return len(s2)\n",
    "        if not s2:\n",
    "            return len(s1)\n",
    "\n",
    "        len_s1 = len(s1)\n",
    "        len_s2 = len(s2)\n",
    "\n",
    "        dp = [[0] * (len_s2 + 1) for _ in range(len_s1 + 1)]\n",
    "\n",
    "        for i in range(len_s1 + 1):\n",
    "            dp[i][0] = i\n",
    "        for j in range(len_s2 + 1):\n",
    "            dp[0][j] = j\n",
    "\n",
    "        for i in range(1, len_s1 + 1):\n",
    "            for j in range(1, len_s2 + 1):\n",
    "                cost = 0 if s1[i-1] == s2[j-1] else 1\n",
    "                dp[i][j] = min(\n",
    "                    dp[i-1][j] + 1,       # deletion\n",
    "                    dp[i][j-1] + 1,       # insertion\n",
    "                    dp[i-1][j-1] + cost   # substitution\n",
    "                )\n",
    "\n",
    "        return dp[len_s1][len_s2]\n",
    "\n",
    "    def compute_per_record_metrics(self, cipher_text: str, gold_label: str) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Compute per-record metrics:\n",
    "          1) Levenshtein Error Rate: dist / len(gold_label)\n",
    "          2) Character Error Rate:   1 - (# matched chars / len(gold_label))\n",
    "          3) Word Accuracy (raw fraction for a single record)\n",
    "          4) Sentence Accuracy: 1.0 if exact match else 0.0\n",
    "        \"\"\"\n",
    "        gold_len = len(gold_label)\n",
    "        \n",
    "        # 1) Levenshtein Error Rate\n",
    "        if gold_len > 0:\n",
    "            dist = self.levenshtein_distance(cipher_text, gold_label)\n",
    "            levenshtein_error_rate = dist / gold_len\n",
    "            # Cap the Levenshtein Error Rate at 100 if it exceeds this threshold\n",
    "            if levenshtein_error_rate > 1:\n",
    "                levenshtein_error_rate = 1.0000\n",
    "                dist = gold_len\n",
    "        else:\n",
    "            dist = 0\n",
    "            levenshtein_error_rate = 0.0\n",
    "\n",
    "        # 2) Character Error Rate\n",
    "        matched_chars = 0\n",
    "        for i in range(gold_len):\n",
    "            if i < len(cipher_text) and cipher_text[i] == gold_label[i]:\n",
    "                matched_chars += 1\n",
    "\n",
    "        if gold_len > 0:\n",
    "            character_error_rate = 1 - (matched_chars / gold_len)\n",
    "        else:\n",
    "            character_error_rate = 0.0\n",
    "\n",
    "        # 3) Word Accuracy (unweighted, just per-record fraction)\n",
    "        gold_words = gold_label.split()\n",
    "        pred_words = cipher_text.split()\n",
    "        matched_words = sum(gw == pw for gw, pw in zip(gold_words, pred_words))\n",
    "        gold_words_len = len(gold_words)\n",
    "\n",
    "        if gold_words_len > 0:\n",
    "            word_accuracy = matched_words / gold_words_len\n",
    "        else:\n",
    "            word_accuracy = 0.0\n",
    "\n",
    "        # 4) Sentence Accuracy\n",
    "        sentence_accuracy = 1.0 if cipher_text == gold_label else 0.0\n",
    "\n",
    "        return {\n",
    "            'levenshtein_error_rate': levenshtein_error_rate,\n",
    "            'character_error_rate': character_error_rate,\n",
    "            'word_accuracy': word_accuracy,     # raw fraction for this record\n",
    "            'sentence_accuracy': sentence_accuracy,\n",
    "            # Additional for file-level weighting\n",
    "            'levenshtein_distance': dist,\n",
    "            'matched_chars': matched_chars,\n",
    "            'gold_length': gold_len,\n",
    "            'matched_words': matched_words,\n",
    "            'gold_words_len': gold_words_len\n",
    "        }\n",
    "\n",
    "    def process_json_file(self, filepath: str, fields: Dict[str, str]) -> Optional[Dict[str, float]]:\n",
    "        \"\"\"\n",
    "        Process a single JSON file:\n",
    "         - For each record: compute per-record metrics and log them.\n",
    "         - For file-level: \n",
    "             * Weighted word accuracy (using L^k).\n",
    "             * Weighted Levenshtein and Character Error Rate.\n",
    "             * Average Sentence Accuracy.\n",
    "             * NEW: total matched words vs. total gold words => file-level average word accuracy.\n",
    "        \"\"\"\n",
    "        filename = os.path.basename(filepath)\n",
    "        try:\n",
    "            with open(filepath, 'r', encoding='utf-8') as f:\n",
    "                content = f.read().strip()\n",
    "                if not content:\n",
    "                    logging.warning(f\"Skipping empty file: {filename}\")\n",
    "                    return None\n",
    "                data = json.loads(content)\n",
    "        except (json.JSONDecodeError, FileNotFoundError):\n",
    "            logging.error(f\"Error reading or decoding JSON in file: {filename}\")\n",
    "            return None\n",
    "\n",
    "        if not isinstance(data, list):\n",
    "            logging.error(f\"File {filename} does not contain a list of records.\")\n",
    "            return None\n",
    "\n",
    "        # Accumulators for file-level (weighted or otherwise)\n",
    "        total_levenshtein_distance = 0\n",
    "        total_matched_chars = 0\n",
    "        total_gold_chars = 0\n",
    "\n",
    "        # Weighted Word Accuracy accumulators\n",
    "        sum_weighted_word_contrib = 0.0\n",
    "        sum_length_weights = 0.0\n",
    "\n",
    "        # Sentence accuracy accumulators\n",
    "        sum_sentence_accuracy = 0.0\n",
    "        record_count = 0\n",
    "\n",
    "        # Accumulators for average word accuracy\n",
    "        total_matched_words = 0\n",
    "        total_gold_words = 0\n",
    "\n",
    "        # Start logging to the details file\n",
    "        with open(self.config.output_details_file, 'a', encoding='utf-8') as out_f:\n",
    "            out_f.write(f\"=== Processing file: {filename} ===\\n\")\n",
    "            out_f.write(f\"Model name: {fields.get('model_name', '')}, Shift: {fields.get('shift', '')}, \"\n",
    "                        f\"Prompt Type: {fields.get('prompt_type', '')}, Temperature: {fields.get('temperature', '')}, \"\n",
    "                        f\"Max Token: {fields.get('max_token', '')}\\n\\n\")\n",
    "\n",
    "            # k exponent for weighting word accuracy\n",
    "            k = self.word_weight_exponent\n",
    "\n",
    "            # Process each record\n",
    "            for idx, record in enumerate(data, start=1):\n",
    "                cipher_text = record.get(\"cipher_text\", \"\").strip()\n",
    "                gold_label = record.get(\"gold_label\", \"\").strip()\n",
    "\n",
    "                if not cipher_text and not gold_label:\n",
    "                    continue\n",
    "\n",
    "                metrics = self.compute_per_record_metrics(cipher_text, gold_label)\n",
    "\n",
    "                # Basic record-level fraction\n",
    "                record_word_acc = metrics['word_accuracy']\n",
    "                L_i = metrics['gold_words_len']\n",
    "\n",
    "                # Weight factor = (L_i^k)\n",
    "                length_weight = (L_i ** k)\n",
    "                # Weighted contribution for word accuracy\n",
    "                weighted_contribution = length_weight * record_word_acc\n",
    "\n",
    "                # Accumulate for file-level\n",
    "                total_levenshtein_distance += metrics['levenshtein_distance']\n",
    "                total_matched_chars += metrics['matched_chars']\n",
    "                total_gold_chars += metrics['gold_length']\n",
    "\n",
    "                # Accumulate for average word accuracy\n",
    "                total_matched_words += metrics['matched_words']\n",
    "                total_gold_words += metrics['gold_words_len']\n",
    "\n",
    "                # Weighted Word Accuracy sums\n",
    "                sum_weighted_word_contrib += weighted_contribution\n",
    "                sum_length_weights += length_weight\n",
    "\n",
    "                sum_sentence_accuracy += metrics['sentence_accuracy']\n",
    "                record_count += 1\n",
    "\n",
    "                # Log per-record details\n",
    "                out_f.write(f\"Record #{idx}\\n\")\n",
    "                out_f.write(f\"  cipher_text: {cipher_text}\\n\")\n",
    "                out_f.write(f\"  gold_label:  {gold_label}\\n\")\n",
    "                out_f.write(f\"  Levenshtein Error Rate: {metrics['levenshtein_error_rate']:.4f}\\n\")\n",
    "                out_f.write(f\"  Character Error Rate:   {metrics['character_error_rate']:.4f}\\n\")\n",
    "                out_f.write(f\"  Word Accuracy (record, raw): {record_word_acc:.4f}\\n\")\n",
    "                out_f.write(f\"  Sentence Accuracy: {metrics['sentence_accuracy']:.4f}\\n\")\n",
    "\n",
    "                # Print matched chars, matched words, gold chars, gold words\n",
    "                out_f.write(f\"  matched_characters: {metrics['matched_chars']}\\n\")\n",
    "                out_f.write(f\"  gold_characters:    {metrics['gold_length']}\\n\")\n",
    "                out_f.write(f\"  matched_words:      {metrics['matched_words']}\\n\")\n",
    "                out_f.write(f\"  gold_words_len:     {metrics['gold_words_len']}\\n\")\n",
    "\n",
    "                # Show the weighting details\n",
    "                out_f.write(f\"  Word length (L_i): {L_i},  k={k},  Weight factor = L_i^k = {length_weight}\\n\")\n",
    "                out_f.write(f\"  Weighted Word Contribution = {length_weight:.2f} * {record_word_acc:.4f} = {weighted_contribution:.4f}\\n\\n\")\n",
    "\n",
    "            # Final file-level Levenshtein Error Rate\n",
    "            if total_gold_chars > 0:\n",
    "                file_levenshtein_error_rate = total_levenshtein_distance / total_gold_chars\n",
    "            else:\n",
    "                file_levenshtein_error_rate = 0.0\n",
    "\n",
    "            # Final file-level Character Error Rate\n",
    "            if total_gold_chars > 0:\n",
    "                file_character_error_rate = 1 - (total_matched_chars / total_gold_chars)\n",
    "            else:\n",
    "                file_character_error_rate = 0.0\n",
    "\n",
    "            # Final Weighted Word Accuracy\n",
    "            if sum_length_weights > 0:\n",
    "                file_weighted_word_accuracy = sum_weighted_word_contrib / sum_length_weights\n",
    "            else:\n",
    "                file_weighted_word_accuracy = 0.0\n",
    "\n",
    "            # Sentence Accuracy (average)\n",
    "            if record_count > 0:\n",
    "                file_sentence_accuracy = sum_sentence_accuracy / record_count\n",
    "            else:\n",
    "                file_sentence_accuracy = 0.0\n",
    "\n",
    "            # NEW: file-level average (unweighted) word accuracy\n",
    "            if total_gold_words > 0:\n",
    "                file_average_word_accuracy = total_matched_words / total_gold_words\n",
    "            else:\n",
    "                file_average_word_accuracy = 0.0\n",
    "\n",
    "            # Write file summary\n",
    "            out_f.write(f\"--- Summary for file: {filename} ---\\n\")\n",
    "            out_f.write(f\"Total records processed: {record_count}\\n\\n\")\n",
    "            out_f.write(f\"Weighted Levenshtein Error Rate (File-level):  {file_levenshtein_error_rate:.4f}\\n\")\n",
    "            out_f.write(f\"Weighted Character Error Rate (File-level):    {file_character_error_rate:.4f}\\n\")\n",
    "            out_f.write(f\"Weighted Word Accuracy (File-level, k={k}):     {file_weighted_word_accuracy:.4f}\\n\")\n",
    "            out_f.write(f\"Average Sentence Accuracy (File-level):        {file_sentence_accuracy:.4f}\\n\")\n",
    "            out_f.write(f\"Average Word Accuracy (File-level, unweighted): {file_average_word_accuracy:.4f}\\n\\n\")\n",
    "\n",
    "            # NEW: file-level totals\n",
    "            out_f.write(f\"File-level totals:\\n\")\n",
    "            out_f.write(f\"  total_characters_in_gold_label: {total_gold_chars}\\n\")\n",
    "            out_f.write(f\"  total_matched_characters:       {total_matched_chars}\\n\")\n",
    "            out_f.write(f\"  total_words_in_gold_label:      {total_gold_words}\\n\")\n",
    "            out_f.write(f\"  total_matched_words:            {total_matched_words}\\n\")\n",
    "            out_f.write(\"==========================================\\n\\n\")\n",
    "\n",
    "        # Return a dictionary of file-level results (used for CSV)\n",
    "        return {\n",
    "            'filename': filename,\n",
    "            'model_name': fields.get('model_name', ''),\n",
    "            'shift': fields.get('shift', ''),\n",
    "            'prompt_type': fields.get('prompt_type', ''),\n",
    "            'temperature': fields.get('temperature', ''),\n",
    "            'max_token': fields.get('max_token', ''),\n",
    "            'levenshtein_error_rate': file_levenshtein_error_rate,\n",
    "            'character_error_rate': file_character_error_rate,\n",
    "            'weighted_word_accuracy': file_weighted_word_accuracy,\n",
    "            'sentence_accuracy': file_sentence_accuracy,\n",
    "            # Include the new average word accuracy in the CSV\n",
    "            'avg_word_accuracy': file_average_word_accuracy\n",
    "        }\n",
    "\n",
    "    def process_directory(self):\n",
    "        \"\"\"\n",
    "        Iterates over all .json files in the directory, processes each, \n",
    "        and accumulates final metrics for CSV output.\n",
    "        \"\"\"\n",
    "        for filename in os.listdir(self.directory):\n",
    "            if filename.endswith('.json'):\n",
    "                filepath = os.path.join(self.directory, filename)\n",
    "                filename_without_ext = filename[:-5]\n",
    "                \n",
    "                # Extract timestamp from filename to match with config\n",
    "                timestamp = self.extract_timestamp(filename_without_ext)\n",
    "                fields = self.config_data.get(timestamp)\n",
    "                \n",
    "                if not fields:\n",
    "                    logging.warning(\n",
    "                        f\"Timestamp '{timestamp}' from filename '{filename_without_ext}' \"\n",
    "                        f\"not found in config file {self.config_file}\"\n",
    "                    )\n",
    "                    continue\n",
    "\n",
    "                file_results = self.process_json_file(filepath, fields)\n",
    "                if file_results:\n",
    "                    self.file_level_results.append(file_results)\n",
    "\n",
    "    def write_csv_results(self):\n",
    "        \"\"\"\n",
    "        Writes the accumulated file-level metrics to a CSV file, including\n",
    "        Weighted Word Accuracy (k=2), Average Word Accuracy, etc.\n",
    "        \"\"\"\n",
    "        csv_file = self.config.csv_file_result\n",
    "\n",
    "        def shift_as_int(val):\n",
    "            try:\n",
    "                return int(val['shift'])\n",
    "            except ValueError:\n",
    "                return 999999  # fallback if not numeric\n",
    "\n",
    "        self.file_level_results.sort(key=lambda x: (x['model_name'], shift_as_int(x), x['prompt_type']))\n",
    "\n",
    "        with open(csv_file, mode='w', newline='', encoding='utf-8') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\n",
    "                'Filename', \n",
    "                'Model', \n",
    "                'Shift', \n",
    "                'Prompt Type', \n",
    "                'Temperature', \n",
    "                'Max Token',\n",
    "                'Levenshtein Error Rate (%)', \n",
    "                'Character Error Rate (%)',\n",
    "                'Weighted Word Accuracy (%)',\n",
    "                'Sentence Accuracy (%)',\n",
    "                'Average Word Accuracy (%)'\n",
    "            ])\n",
    "            for res in self.file_level_results:\n",
    "                writer.writerow([\n",
    "                    res['filename'],\n",
    "                    res['model_name'],\n",
    "                    res['shift'],\n",
    "                    res['prompt_type'],\n",
    "                    res['temperature'],\n",
    "                    res['max_token'],\n",
    "                    f\"{res['levenshtein_error_rate'] * 100:.2f}\",\n",
    "                    f\"{res['character_error_rate'] * 100:.2f}\",\n",
    "                    f\"{res['weighted_word_accuracy'] * 100:.2f}\",\n",
    "                    f\"{res['sentence_accuracy'] * 100:.2f}\",\n",
    "                    f\"{res['avg_word_accuracy'] * 100:.2f}\"\n",
    "                ])\n",
    "        logging.info(f\"CSV results written to '{csv_file}'\")\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Main entry point: processes the JSON files, then writes final CSV results.\n",
    "        \"\"\"\n",
    "        self.process_directory()\n",
    "        self.write_csv_results()\n",
    "        logging.info(f\"Processing finished.\\n\"\n",
    "                     f\"  - Detailed record-level results: '{self.config.output_details_file}'\\n\"\n",
    "                     f\"  - File-level summary CSV: '{self.config.csv_file_result}'\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    config = Config()\n",
    "    caesar_test = CaesarCipherTest(config)\n",
    "    caesar_test.run()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
