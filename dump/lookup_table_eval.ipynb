{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8baaeeeb-4aef-4f82-bab3-d30109d3099c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: The file ./data/encoded/experiments/20240912_194832.json is empty, skipping.\n",
      "Warning: The file ./data/encoded/experiments/20240912_194832.json is empty, skipping.\n",
      "Warning: The file ./data/encoded/experiments/20240912_194832.json is empty, skipping.\n",
      "Warning: The file ./data/encoded/experiments/20240912_194832.json is empty, skipping.\n",
      "Warning: The file ./data/encoded/experiments/20240912_194832.json is empty, skipping.\n",
      "Warning: The file ./data/encoded/experiments/20240912_194832.json is empty, skipping.\n",
      "Warning: The file ./data/encoded/experiments/20240912_194832.json is empty, skipping.\n",
      "All tasks completed successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import ast\n",
    "\n",
    "# Task 1: Reading config1.txt and extracting lines with \"cot-like\"\n",
    "def extract_cot_like_lines(input_file, output_file):\n",
    "    \"\"\"\n",
    "    Reads the input file line by line, extracts lines containing 'cot-like',\n",
    "    and appends them to the output file.\n",
    "    \"\"\"\n",
    "    with open(input_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    # Extract lines containing 'cot-like'\n",
    "    cot_like_lines = [line for line in lines if 'cot-like' in line]\n",
    "\n",
    "    # Write or append to the output file\n",
    "    os.makedirs(os.path.dirname(output_file), exist_ok=True)  # Ensure the directory exists\n",
    "    mode = 'a' if os.path.exists(output_file) else 'w'\n",
    "\n",
    "    with open(output_file, mode) as f:\n",
    "        f.writelines(cot_like_lines)\n",
    "\n",
    "# Task 2: Extract lookup tables based on timestamp and shift\n",
    "def read_lookup_table_from_file(file_path):\n",
    "    \"\"\"\n",
    "    Reads the lookup table from a given file. Skips empty files.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if os.path.getsize(file_path) == 0:  # Check if the file is empty\n",
    "            print(f\"Warning: The file {file_path} is empty, skipping.\")\n",
    "            return None\n",
    "        \n",
    "        with open(file_path, 'r') as f:\n",
    "            lookup_table_data = json.load(f)  # Adjust according to the file format\n",
    "        return lookup_table_data\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error reading lookup table from {file_path}: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error when reading {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def extract_lookup_tables_from_files(input_file, output_file, base_data_dir, shifts):\n",
    "    \"\"\"\n",
    "    Reads lines from the input file, extracts corresponding lookup tables based on timestamps,\n",
    "    and stores them in a structured output JSON file.\n",
    "    \"\"\"\n",
    "    with open(input_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    constructed_lookup_table = {}\n",
    "\n",
    "    for line in lines:\n",
    "        # Extract timestamp and shift\n",
    "        timestamp = line.split('_')[0] + \"_\" + line.split('_')[1]\n",
    "        shift = int(line.split('_')[3])\n",
    "\n",
    "        if shift not in shifts:\n",
    "            print(f\"Warning: Skipping unsupported shift value {shift} in line: {line}\")\n",
    "            continue\n",
    "        \n",
    "        # Construct file path\n",
    "        matching_files = [file for file in os.listdir(base_data_dir) if file.startswith(timestamp)]\n",
    "        if not matching_files:\n",
    "            print(f\"Warning: No matching file found for timestamp: {timestamp}\")\n",
    "            continue\n",
    "\n",
    "        file_path = os.path.join(base_data_dir, matching_files[0])\n",
    "\n",
    "        # Read the lookup table from the file\n",
    "        lookup_table_data = read_lookup_table_from_file(file_path)\n",
    "        if lookup_table_data:\n",
    "            constructed_lookup_table[timestamp] = {\n",
    "                \"shift\": shift,\n",
    "                \"lookup_table\": lookup_table_data\n",
    "            }\n",
    "\n",
    "    # Save the constructed lookup table to output file\n",
    "    os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(constructed_lookup_table, f, indent=4)\n",
    "\n",
    "# Task 3: Compare lookup tables\n",
    "def read_lookup_table(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        return json.load(file)\n",
    "\n",
    "def compare_lookup_tables(constructed_lookup_table_path, golden_lookup_table_path, output_json_path):\n",
    "    # Read the constructed and golden lookup tables\n",
    "    constructed_table = read_lookup_table(constructed_lookup_table_path)\n",
    "    golden_table = read_lookup_table(golden_lookup_table_path)\n",
    "    \n",
    "    # Prepare the output structure\n",
    "    results = {\n",
    "        \"file_evaluation\": {},\n",
    "        \"total_mappings\": 0,\n",
    "        \"correct_mappings\": 0,\n",
    "        \"details\": []\n",
    "    }\n",
    "    \n",
    "    # Process each entry in the constructed lookup table\n",
    "    for entry_key, entry in constructed_table.items():\n",
    "        if \"lookup_table\" in entry:\n",
    "            shift = entry[\"shift\"]\n",
    "            results[\"file_evaluation\"][entry_key] = {\n",
    "                \"correct\": 0,\n",
    "                \"total\": 0\n",
    "            }\n",
    "\n",
    "            # Get the corresponding golden lookup table based on the shift\n",
    "            golden_shift_key = f\"shift_{shift}\"\n",
    "            golden_lookup_table = golden_table.get(golden_shift_key, {})\n",
    "            \n",
    "            for mapping in entry[\"lookup_table\"]:\n",
    "                if isinstance(mapping, dict):  # Ensure mapping is a dict\n",
    "                    plain_text = mapping.get(\"plain_text\", \"\")\n",
    "                    constructed_lookup = mapping.get(\"lookup_table\", {})\n",
    "                    \n",
    "                    # Handle case where lookup_table is a string and needs conversion to a dict\n",
    "                    if isinstance(constructed_lookup, str):\n",
    "                        try:\n",
    "                            constructed_lookup = ast.literal_eval(constructed_lookup)\n",
    "                        except (SyntaxError, ValueError):\n",
    "                            print(f\"Warning: Failed to parse constructed lookup table for entry {plain_text}. Skipping comparison.\")\n",
    "                            continue\n",
    "                    \n",
    "                    # Ensure both constructed and golden lookup tables are dicts\n",
    "                    if not isinstance(constructed_lookup, dict) or not isinstance(golden_lookup_table, dict):\n",
    "                        print(f\"Warning: Invalid lookup table format for {plain_text}. Skipping comparison.\")\n",
    "                        continue\n",
    "\n",
    "                    # Compare constructed lookup table with golden lookup table\n",
    "                    correct_mappings = 0\n",
    "                    total_mappings = 0\n",
    "                    for key, value in constructed_lookup.items():\n",
    "                        total_mappings += 1\n",
    "                        if key in golden_lookup_table and golden_lookup_table[key] == value:\n",
    "                            correct_mappings += 1\n",
    "\n",
    "                    results[\"total_mappings\"] += total_mappings\n",
    "                    results[\"correct_mappings\"] += correct_mappings\n",
    "                    results[\"file_evaluation\"][entry_key][\"total\"] += total_mappings\n",
    "                    results[\"file_evaluation\"][entry_key][\"correct\"] += correct_mappings\n",
    "                    \n",
    "                    # Add details for this mapping\n",
    "                    results[\"details\"].append({\n",
    "                        \"plain_text\": plain_text,\n",
    "                        \"shift\": shift,\n",
    "                        \"matched\": correct_mappings == total_mappings,\n",
    "                        \"total_mappings\": total_mappings,\n",
    "                        \"correct_mappings\": correct_mappings,\n",
    "                        \"constructed_lookup\": constructed_lookup,\n",
    "                        \"gold_lookup\": golden_lookup_table\n",
    "                    })\n",
    "\n",
    "    # Calculate percentage for each file\n",
    "    for entry_key, entry in results[\"file_evaluation\"].items():\n",
    "        if entry[\"total\"] > 0:\n",
    "            percentage = (entry[\"correct\"] / entry[\"total\"]) * 100\n",
    "            results[\"file_evaluation\"][entry_key] = f\"{percentage:.2f}%\"\n",
    "        else:\n",
    "            results[\"file_evaluation\"][entry_key] = \"0%\"\n",
    "\n",
    "    # Save results to a JSON file\n",
    "    with open(output_json_path, 'w') as output_file:\n",
    "        json.dump(results, output_file, indent=4)\n",
    "\n",
    "\n",
    "\n",
    "# Paths\n",
    "config1_path = \"./config1.txt\"\n",
    "cot_like_output_path = \"./eval/lookup_table/lookup_table_files.txt\"\n",
    "base_data_dir = \"./data/encoded/experiments/\"\n",
    "constructed_lookup_table_path = './eval/lookup_table/constructed_lookup_table.json'\n",
    "golden_lookup_table_path = './eval/lookup_table/golden_lookup_table.json'\n",
    "output_json_path = './eval/lookup_table/evaluation_result_lookup_table.json'\n",
    "\n",
    "# Task 1: Extract cot-like lines from config1.txt\n",
    "extract_cot_like_lines(config1_path, cot_like_output_path)\n",
    "\n",
    "# Task 2: Extract lookup tables based on timestamp and shift from cot-like files\n",
    "shifts = [3, 6, 9, 12]  # Define supported shifts\n",
    "extract_lookup_tables_from_files(cot_like_output_path, constructed_lookup_table_path, base_data_dir, shifts)\n",
    "\n",
    "# Task 3: Compare lookup tables and output accuracy\n",
    "compare_lookup_tables(constructed_lookup_table_path, golden_lookup_table_path, output_json_path)\n",
    "print(\"All tasks completed successfully.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
